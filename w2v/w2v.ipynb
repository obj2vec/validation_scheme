{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/akutuzov/webvectors/blob/master/preprocessing/rusvectores_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, zipfile\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"SimLex-999.txt\", 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_part(word, part):\n",
    "    if part == 'A':\n",
    "        return word+'_ADV'\n",
    "    if part == 'N':\n",
    "        return word+'_NOUN'\n",
    "    if part == 'V':\n",
    "        return word+'_VERB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(model_file, part=False):\n",
    "    with zipfile.ZipFile(model_file, 'r') as archive:\n",
    "        stream = archive.open('model.bin')\n",
    "        model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)\n",
    "        \n",
    "    #model.distance('apple', 'orange')\n",
    "    \n",
    "    not_in_model=[]\n",
    "    w2v_pairs=[]\n",
    "    for i in f[1:]:\n",
    "        ii=i.split('\\t')\n",
    "        first_word=ii[0]\n",
    "        second_word=ii[1]\n",
    "        if part:\n",
    "            first_word=add_part(first_word, ii[2])\n",
    "            second_word=add_part(second_word, ii[2])\n",
    "        flag=0\n",
    "        if first_word not in model:\n",
    "            not_in_model.append(first_word.split('_')[0])\n",
    "            flag=1\n",
    "        if second_word not in model:\n",
    "            not_in_model.append(second_word.split('_')[0])\n",
    "            flag=1\n",
    "        if not flag:\n",
    "            w2v_pairs.append(model.distance(first_word, second_word))\n",
    "        #print(first_word, second_word)\n",
    "    print(len(w2v_pairs), not_in_model)\n",
    "    \n",
    "    simlex_pairs=[]\n",
    "    for i in f[1:]:\n",
    "        ii=i.split('\\t')\n",
    "        if ii[0] not in not_in_model and ii[1] not in not_in_model:\n",
    "            simlex_pairs.append(float(ii[3]))\n",
    "    print(len(simlex_pairs))\n",
    "    \n",
    "    return spearmanr(simlex_pairs, w2v_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сначала попробуем без лемматизации\n",
    "\n",
    "6 \tDownload \t300 \t5 \tEnglish Wikipedia Dump of February 2017\n",
    "\t302866 \tGensim Continuous Skipgram \tFalse\n",
    "\n",
    "http://vectors.nlpl.eu/repository/20/6.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995 ['suds', 'disorganize', 'do', 'do']\n",
      "995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.39646198627096135, pvalue=8.504530329272487e-39)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank('6.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это очень странный результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, and what about with lemmatize\n",
    "\n",
    "5 \tDownload \t300 \t5 \tEnglish Wikipedia Dump of February 2017\n",
    "\t273992 \tGensim Continuous Skipgram \tTrue\n",
    "\n",
    "http://vectors.nlpl.eu/repository/20/5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997 ['do', 'do']\n",
      "997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.41016792963353155, pvalue=9.714938327555687e-42)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank('5.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод в том, что лемматизация не сильно влияет на качество представлений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем более новый корпус Википедии, также с лемматизацией\n",
    "\n",
    "Download \t300 \t3 \tEnglish Wikipedia Dump of October 2019\n",
    "\t249212 \tGensim Continuous Skipgram \tTrue\n",
    "\n",
    "http://vectors.nlpl.eu/repository/20/200.zip\n",
    "\n",
    "Эта модель содержит части речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894 ['new', 'smart', 'intelligent', 'difficult', 'happy', 'cheerful', 'easy', 'rapid', 'happy', 'glad', 'stupid', 'dumb', 'weird', 'strange', 'awful', 'easy', 'difficult', 'terrible', 'simple', 'smart', 'dumb', 'crazy', 'happy', 'mad', 'large', 'huge', 'new', 'dull', 'rapid', 'dumb', 'foolish', 'wonderful', 'terrific', 'strange', 'odd', 'happy', 'angry', 'broad', 'simple', 'easy', 'apparent', 'obvious', 'inexpensive', 'cheap', 'nice', 'generous', 'weird', 'normal', 'weird', 'odd', 'immoral', 'sad', 'funny', 'wonderful', 'great', 'guilty', 'ashamed', 'beautiful', 'wonderful', 'confident', 'dumb', 'dense', 'large', 'big', 'nice', 'cruel', 'impatient', 'anxious', 'big', 'broad', 'proud', 'unnecessary', 'necessary', 'restless', 'dumb', 'intelligent', 'great', 'difficult', 'simple', 'necessary', 'important', 'terrific', 'mad', 'glad', 'honest', 'guilty', 'easy', 'easy', 'flexible', 'certain', 'essential', 'necessary', 'different', 'normal', 'crucial', 'important', 'harsh', 'cruel', 'childish', 'foolish', 'rare', 'friendly', 'generous', 'fragile', 'frigid', 'big', 'frigid', 'strange', 'illegal', 'immoral', 'guilty', 'modern', 'ancient', 'new', 'ancient', 'dull', 'funny', 'happy', 'easy', 'big', 'great', 'awful', 'tiny', 'huge', 'polite', 'modest', 'ashamed', 'exotic', 'rare', 'dumb', 'delightful', 'wonderful', 'noticeable', 'obvious', 'afraid', 'anxious', 'formal', 'dreary', 'dull', 'delightful', 'cheerful', 'unhappy', 'mad', 'sad', 'terrible', 'sick', 'crazy', 'violent', 'angry', 'dirty', 'cheap', 'elastic', 'flexible', 'dense', 'recent', 'new', 'bold', 'proud', 'strange', 'strange', 'dumb', 'rare', 'terrific', 'mad', 'modest', 'flexible', 'huge', 'dumb', 'large', 'flexible', 'dirty', 'suds', 'august', 'bias']\n",
      "894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.4162699520761669, pvalue=8.844670518902433e-39)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank('200.zip', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат не сильно отличается"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
